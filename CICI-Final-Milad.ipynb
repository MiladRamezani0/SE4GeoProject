{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7f8888a3",
   "metadata": {},
   "source": [
    "\n",
    "## <span style=\"color:gold\">CICI Group Project</span>\n",
    "\n",
    "\n",
    "\n",
    "## <span style=\"color:gold\">Air Quality Report with Jupyter Notebook dashboard</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "926475fa",
   "metadata": {},
   "source": [
    ".\n",
    "\n",
    "\n",
    "## <span style=\"color:green\">CICI_BackEnd</span>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "4eb2028a-1be0-46ce-8d8d-0443bd6f9fc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dash is running on http://127.0.0.1:9012/\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe\n",
       "            width=\"100%\"\n",
       "            height=\"650\"\n",
       "            src=\"http://127.0.0.1:9012/\"\n",
       "            frameborder=\"0\"\n",
       "            allowfullscreen\n",
       "            \n",
       "        ></iframe>\n",
       "        "
      ],
      "text/plain": [
       "<IPython.lib.display.IFrame at 0x23b5d460110>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "###...<<< Import libraries >>>...###\n",
    "from flask import Flask,jsonify,request\n",
    "import json \n",
    "from sqlalchemy import create_engine, text\n",
    "import os\n",
    "import requests\n",
    "import geopandas as gpd\n",
    "import psycopg2\n",
    "import geoalchemy2\n",
    "from jupyter_dash import JupyterDash\n",
    "import dash\n",
    "from dash import dcc\n",
    "from dash import html\n",
    "JupyterDash.infer_jupyter_proxy_config()\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from ipywidgets import interact, Dropdown\n",
    "import folium\n",
    "import numpy as np\n",
    "import ipywidgets as widgets\n",
    "from IPython.display import display\n",
    "from matplotlib.colors import Normalize\n",
    "import shapely \n",
    "import plotly.graph_objects as go\n",
    "from folium.plugins import HeatMap\n",
    "from folium import IFrame\n",
    "import plotly.express as px\n",
    "import folium.plugins as plugins\n",
    "import base64\n",
    "\n",
    "# print('\\n Import libraries Done!!!')\n",
    "# ###...<<< download Data from the https://discomap.eea.europa.eu/map/fme/AirQualityUTDExport.htm >>>...###\n",
    "# # Set the directory path to save the files\n",
    "# save_directory = \"E:/Plimi/01 - First Term/03 - Software Engineering For Geoinformatics/05 - Project/03 - python code/CICI-Group-Project/CICI_Data\"\n",
    "# # Rest of your code\n",
    "# #print('-----------------------------------------------------------------------')\n",
    "# # Set download url\n",
    "# ServiceUrl = \"http://discomap.eea.europa.eu/map/fme/latest\"\n",
    "# # Countries to download\n",
    "# # Note: List is not complete['IT','DE']#\n",
    "# countries = ['AD','AT','BA','BG','CZ','DE','DK','EE','GI','HR','IE','IS','LT','LU','LV','NL','PL','PT','SE','BE','CY','ES','FR','GR','HU','IT','MT','NO','XK','FI','GB','RS','SI','SK','CH']\n",
    "# # Pollutant to be downloaded\n",
    "# pollutants = ['NO2','O3','CO','SO2','PM2.5','PM10','NO']\n",
    "# for country in countries:\n",
    "#     for pollutant in pollutants:\n",
    "#         fileName = \"%s_%s.csv\" % (country, pollutant)\n",
    "#         downloadFile = '%s/%s_%s.csv' % (ServiceUrl, country, pollutant)\n",
    "#         # Download and save to local path\n",
    "#         #print('Downloading: %s' % downloadFile )\n",
    "#         file = requests.get(downloadFile).content\n",
    "#         output_path = os.path.join(save_directory, fileName)\n",
    "#         with open(output_path, 'wb') as output:\n",
    "#             output.write(file)\n",
    "#         #print('Saved locally as: %s' % output_path)\n",
    "#         #print('-----')\n",
    "# print('Download finished')\n",
    "################################################################DATA BASE #####################################################\n",
    "# # Setup db connection (generic connection path to be update with your credentials: 'postgresql://user:password@localhost:5432/mydatabase')\n",
    "# engine = create_engine('postgresql://postgres:mrzk1234@localhost:5432/se4g') \n",
    "# con = engine.connect()\n",
    "# con\n",
    "# data=gpd.read_file(r\"E:/Plimi/01 - First Term/03 - Software Engineering For Geoinformatics/05 - Project/03 - python code/CICI-Group-Project/CICI_Data/01_Data/CICI_Data.csv\")\n",
    "# print(\"Done!!!\")\n",
    "# #save data to sql\n",
    "# data.to_sql('CICI_Data', engine, if_exists = 'replace', index=False)\n",
    "# print(\"Done!!!\")\n",
    "################################################################DATA BASE #####################################################\n",
    "# Directory containing the CSV files\n",
    "directory = r\"E:/Plimi/01 - First Term/03 - Software Engineering For Geoinformatics/05 - Project/03 - python code/CICI-Group-Project/CICI_Data\"\n",
    "# Initialize an empty list to store the DataFrames\n",
    "dataframes = []\n",
    "# Iterate over each file in the directory\n",
    "for filename in os.listdir(directory):\n",
    "    if filename.endswith(\".csv\"):\n",
    "        file_path = os.path.join(directory, filename)\n",
    "        \n",
    "        # Check the file size in bytes\n",
    "        file_size = os.path.getsize(file_path)\n",
    "        if file_size < 15360:  # File size less than 15 KB\n",
    "            continue  # Skip this file\n",
    "        \n",
    "        # Read the CSV file into a DataFrame\n",
    "        df = pd.read_csv(file_path)\n",
    "        # Append the DataFrame to the list\n",
    "        dataframes.append(df)\n",
    "# Concatenate all the DataFrames into a single DataFrame\n",
    "merged_data = pd.concat(dataframes, ignore_index=True)\n",
    "# Delete rows with negative values in value_numeric column\n",
    "merged_data = merged_data[merged_data['value_numeric'] >= 0]\n",
    "# Specify the column containing the date and time values\n",
    "column_name = 'value_datetime_begin'\n",
    "# Convert the column to datetime format\n",
    "merged_data[column_name] = pd.to_datetime(merged_data[column_name])\n",
    "# Create new columns for time and date\n",
    "merged_data['Time'] = merged_data[column_name].dt.time\n",
    "merged_data['Date'] = merged_data[column_name].dt.date\n",
    "# Remove the original datetime column\n",
    "merged_data.drop(columns=[column_name], inplace=True)\n",
    "# Drop rows with missing values in 'value_numeric' column\n",
    "merged_data.dropna(subset=['value_numeric'], inplace=True)\n",
    "###...<<< delete some columns >>>...###\n",
    "###...<<< and insert country full name >>>...###\n",
    "# List of columns to be deleted\n",
    "columns_to_delete = ['network_localid', 'network_name', 'network_namespace','network_timezone', 'samplingpoint_localid', 'samplingpoint_namespace','station_localid', 'station_namespace', 'value_datetime_end','value_datetime_inserted', 'value_datetime_updated', 'value_validity', 'value_verification']  \n",
    "# Delete the columns from the DataFrame\n",
    "merged_data = merged_data.drop(columns=columns_to_delete)\n",
    "# Define a dictionary mapping symbols to names\n",
    "country_mapping = {\n",
    "    'AD': 'Andorra','AT': 'Austria','BA': 'Bosnia and Herzegovina','BG': 'Bulgaria','CZ': 'Czech Republic','DE': 'Germany','DK': 'Denmark','EE': 'Estonia','GI': 'Gibraltar','HR': 'Croatia','IE': 'Ireland','IS': 'Iceland','LT': 'Lithuania','LU': 'Luxembourg','LV': 'Latvia','NL': 'Netherlands','PL': 'Poland','PT': 'Portugal','SE': 'Sweden','BE': 'Belgium','CY': 'Cyprus','ES': 'Spain','FR': 'France','GR': 'Greece','HU': 'Hungary','IT': 'Italy','MT': 'Malta','NO': 'Norway','XK': 'Kosovo','FI': 'Finland','GB': 'United Kingdom','RS': 'Serbia','SI': 'Slovenia','SK': 'Slovakia','CH': 'Switzerland'\n",
    "}\n",
    "# Replace symbols with names in the specified column\n",
    "merged_data['network_countrycode'] = merged_data['network_countrycode'].replace(country_mapping)\n",
    "# Create a dictionary of country coordinates\n",
    "country_coordinates = {\n",
    "    'Albania': (41.1533, 20.1683),'Andorra': (42.5462, 1.6016),'Austria': (47.5162, 14.5501),'Belarus': (53.7098, 27.9534),'Belgium': (50.5039, 4.4699),'Bosnia and Herzegovina': (43.9159, 17.6791),'Bulgaria': (42.7339, 25.4858),'Croatia': (45.1000, 15.2000),'Cyprus': (35.1264, 33.4299),'Czech Republic': (49.8175, 15.4730),'Denmark': (56.2639, 9.5018),'Estonia': (58.5953, 25.0136),'Finland': (61.9241, 25.7482),'France': (46.6034, 1.8883),'Germany': (51.1657, 10.4515),'Gibraltar': (36.14, 5.35),'Greece': (39.0742, 21.8243),'Hungary': (47.1625, 19.5033),'Iceland': (64.9631, -19.0208),'Ireland': (53.4129, -8.2439),'Italy': (41.8719, 12.5674),'Kosovo': (42.6026, 20.9030),'Latvia': (56.8796, 24.6032),'Liechtenstein': (47.1660, 9.5554),'Lithuania': (55.1694, 23.8813),'Luxembourg': (49.8153, 6.1296),'Malta': (35.9375, 14.3754),'Moldova': (47.4116, 28.3699),'Monaco': (43.7384, 7.4246),'Montenegro': (42.7087, 19.3744),'Netherlands': (52.1326, 5.2913),'North Macedonia': (41.6086, 21.7453),'Norway': (60.4720, 8.4689),'Poland': (51.9194, 19.1451),'Portugal': (39.3999, -8.2245),'Romania': (45.9432, 24.9668),'Russia': (61.5240, 105.3188),'San Marino': (43.9424, 12.4578),'Serbia': (44.0165, 21.0059),'Slovakia': (48.6690, 19.6990),'Slovenia': (46.1512, 14.9955),'Spain': (40.4637, -3.7492),'Sweden': (60.1282, 18.6435),'Switzerland': (46.8182, 8.2275),'Ukraine': (48.3794, 31.1656),'United Kingdom': (55.3781, -3.4360),'Vatican City': (41.9029, 12.4534)\n",
    "}\n",
    "# Convert non-numeric values in value_numeric to NaN\n",
    "merged_data['value_numeric'] = pd.to_numeric(merged_data['value_numeric'], errors='coerce')\n",
    "# Group the data by network_countrycode, pollutant, and value_unit\n",
    "mean_samplingpoint = merged_data.groupby(['network_countrycode', 'pollutant'])['value_numeric'].mean(numeric_only=True).reset_index()\n",
    "# Add the unit and station name columns\n",
    "mean_samplingpoint['unit'] = mean_samplingpoint.apply(lambda row: merged_data.loc[(merged_data['network_countrycode'] == row['network_countrycode']) & (merged_data['pollutant'] == row['pollutant']), 'value_unit'].iloc[0], axis=1)\n",
    "mean_samplingpoint['station_name'] = mean_samplingpoint.apply(lambda row: merged_data.loc[(merged_data['network_countrycode'] == row['network_countrycode']) & (merged_data['pollutant'] == row['pollutant']), 'station_name'].iloc[0], axis=1)\n",
    "# Add the coordinates for each country\n",
    "mean_samplingpoint['coordinates'] = mean_samplingpoint['network_countrycode'].map(country_coordinates)\n",
    "# Add the samplingpoint_x and samplingpoint_y columns\n",
    "mean_samplingpoint['samplingpoint_x'] = mean_samplingpoint['coordinates'].apply(lambda coord: coord[0])\n",
    "mean_samplingpoint['samplingpoint_y'] = mean_samplingpoint['coordinates'].apply(lambda coord: coord[1])\n",
    "##########################################################################################################################################################################################################################\n",
    "# Filter the data based on user-selected country and pollution\n",
    "def filter_data(country, pollutant):\n",
    "    filtered_data = merged_data[(merged_data['network_countrycode'] == country) & (merged_data['pollutant'] == pollutant)]\n",
    "    return filtered_data.tail(48)  # Limit the data to the last 48 rows\n",
    "######################popUp#########################\n",
    "# Group the data by network_countrycode, pollutant, and value_unit\n",
    "mean_samplingpoint = merged_data.groupby(['network_countrycode', 'pollutant'])[['samplingpoint_x', 'samplingpoint_y', 'value_numeric', 'value_unit']].mean(numeric_only=True).reset_index()\n",
    "# Add a column to show the unit of data\n",
    "mean_samplingpoint['unit'] = mean_samplingpoint.apply(lambda row: merged_data.loc[(merged_data['network_countrycode'] == row['network_countrycode']) & (merged_data['pollutant'] == row['pollutant']), 'value_unit'].iloc[0], axis=1)\n",
    "# Add the station name column\n",
    "mean_samplingpoint['station_name'] = mean_samplingpoint.apply(lambda row: merged_data.loc[(merged_data['network_countrycode'] == row['network_countrycode']) & (merged_data['pollutant'] == row['pollutant']), 'station_name'].iloc[0], axis=1)\n",
    "# Create a dropdown menu to select the pollution type\n",
    "pollution_types = mean_samplingpoint['pollutant'].unique()\n",
    "# Create a map centered on Europe\n",
    "latitude_center = 38.77  \n",
    "longitude_center = 9.18  \n",
    "zoom_level = 4  # Specify the initial zoom level for the map\n",
    "mape = folium.Map(location=[latitude_center, longitude_center], zoom_start=zoom_level)\n",
    "# Create a dictionary to store the popup messages for each country\n",
    "country_popups = {}\n",
    "# Iterate over the data to create the popup messages\n",
    "for index, row in mean_samplingpoint.iterrows():\n",
    "    country = row['network_countrycode']\n",
    "    pollutant = row['pollutant']\n",
    "    value = round(row['value_numeric'], 3)  # Round the value to 3 decimal places\n",
    "    unit = row['unit']\n",
    "    station_name = row['station_name']  # Retrieve the station name    \n",
    "    # Create a message for the current pollutant\n",
    "    pollutant_message = f\"<b>Pollutant:</b> {pollutant}<br><b>Value:</b> {value} {unit}<br><b>Station:</b> {station_name}<br>\"\n",
    "    # Add the pollutant message to the country's popup message\n",
    "    if country in country_popups:\n",
    "        country_popups[country] += \"<br>\" + pollutant_message\n",
    "    else:\n",
    "        country_popups[country] = f\"<b>Country:</b> {country}<hr>{pollutant_message}\"\n",
    "# Create a single popup for each country with multiple sections\n",
    "for country, popup_message in country_popups.items():\n",
    "    # Create the popup message for the country\n",
    "    country_popup = folium.Popup(popup_message, max_width=900, max_height=600)\n",
    "    # Add a marker for the country with the custom popup\n",
    "    folium.Marker(location=country_coordinates[country], popup=country_popup).add_to(mape)  \n",
    "#############################EndPopUp####################\n",
    "#############################Pollution Data by Country####################\n",
    "############################################\n",
    "# Initialize the JupyterDash app\n",
    "app = JupyterDash(__name__)\n",
    "# Create dropdown widgets for country selection\n",
    "country_dropdown = dcc.Dropdown(\n",
    "    options=[{'label': country, 'value': country} for country in merged_data['network_countrycode'].unique()],\n",
    "    value=merged_data['network_countrycode'].unique()[0],\n",
    "    id='country-dropdown',\n",
    "    clearable=False\n",
    ")\n",
    "# Create a radio bar for pollutant selection\n",
    "pollutant_radio = dcc.RadioItems(\n",
    "    options=[{'label': pollutant, 'value': pollutant} for pollutant in merged_data['pollutant'].unique()],\n",
    "    value=merged_data['pollutant'].unique()[0],\n",
    "    labelStyle={'display': 'inline-block', 'margin': '10px'},\n",
    "    id='pollutant-radio'\n",
    ")\n",
    "# Create an output div for displaying the chart or error message\n",
    "output = html.Div(id='output-div')\n",
    "#############################################################\n",
    "# Create a function to generate the heatmap based on the selected pollution type\n",
    "def generate_heatmap(pollution_type):\n",
    "    filtered_data = mean_samplingpoint[mean_samplingpoint['pollutant'] == pollution_type]\n",
    "\n",
    "    heatmap = folium.Map(\n",
    "        location=[latitude_center, longitude_center],\n",
    "        zoom_start=zoom_level,\n",
    "        tiles='CartoDB dark_matter'\n",
    "    )\n",
    "    if len(filtered_data) == 0:\n",
    "        # Add a red marker to the center if no data is available\n",
    "        folium.Marker(\n",
    "            location=[latitude_center, longitude_center],\n",
    "            icon=folium.Icon(color='red', icon='info-sign'),\n",
    "        ).add_to(heatmap)\n",
    "    else:\n",
    "        # Create a heatmap layer\n",
    "        heat_data = [[row['samplingpoint_y'], row['samplingpoint_x'], row['value_numeric']] for _, row in filtered_data.iterrows()]\n",
    "        heatmap_layer = plugins.HeatMap(heat_data)\n",
    "        heatmap_layer.add_to(heatmap)\n",
    "    return heatmap._repr_html_()\n",
    "#############################################################\n",
    "\n",
    "# Define the app layout\n",
    "app.layout = html.Div(\n",
    "    # style={'backgroundColor': 'black'},  # Set the background color to black\n",
    "    children=[\n",
    "        html.H1(\"Pollution Dashboard\"),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.H2(\"----------------------------------------- Measurement of pollution in different country in the last 48 hours -----------------------------------------\"),\n",
    "        html.Div([\n",
    "            html.Label(\"Select Country:\"),\n",
    "            country_dropdown,\n",
    "            html.Label(\"Select Pollutant:\"),\n",
    "            pollutant_radio\n",
    "        ]),\n",
    "        dcc.Graph(id='graph'),  # Add the graph component with the id 'graph'\n",
    "        output,\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.H2(\"----------------------------------------------- Each country's average pollution in the 48 hours prior -----------------------------------------------\"),\n",
    "        html.Iframe(srcDoc=mape._repr_html_(), width='100%', height='500'),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.H2(\"------------------------------------------------ Pollution Data by Country in the 48 hours prior ------------------------------------------------\"),\n",
    "        html.Label(\"Select Pollution Type:\"),\n",
    "        dcc.Dropdown(\n",
    "            id='pollution-dropdown',\n",
    "            options=[{'label': pt, 'value': pt} for pt in pollution_types],\n",
    "            value=pollution_types[0]\n",
    "        ),\n",
    "        dcc.Graph(id='pollution-graph'),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.H2(\"------------------------------------------------ Display the 48-hour pollution heatmap by country ------------------------------------------------\"),\n",
    "        html.Div(\n",
    "            id='radio-bar-container',\n",
    "            style={'display': 'flex', 'alignItems': 'center', 'justifyContent': 'center'},\n",
    "            children=[\n",
    "                html.Label(\"Pollution Type\"),\n",
    "                dcc.RadioItems(\n",
    "                    id='pollution-type-radio',\n",
    "                    options=[{'label': pollutant_name, 'value': pollutant_name} for pollutant_name in mean_samplingpoint['pollutant'].unique()],\n",
    "                    value=mean_samplingpoint['pollutant'].unique()[0],\n",
    "                    labelStyle={'display': 'inline-block', 'margin': '10px'}\n",
    "                )\n",
    "            ]\n",
    "        ),\n",
    "        html.Div(id='map-container', children=[html.Iframe(srcDoc='', id='map-iframe', width='100%', height='500')]),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.Hr(),\n",
    "        html.H2(\"------------------------------------------------ Download CSV Files ------------------------------------------------\"),\n",
    "        html.Div([\n",
    "            html.A('Download merged_data CSV', id='download-merged-data', download='merged_data.csv', href='', target='_blank'),\n",
    "            html.Br(),\n",
    "            html.A('Download mean_samplingpoint CSV', id='download-mean-samplingpoint', download='mean_samplingpoint.csv', href='', target='_blank')\n",
    "        ])\n",
    "    ]\n",
    ")\n",
    "\n",
    "@app.callback(\n",
    "    Output('pollution-graph', 'figure'),\n",
    "    Input('pollution-dropdown', 'value')\n",
    ")\n",
    "def update_graph(selected_pollution):\n",
    "    # Filter the data for the selected pollution type\n",
    "    selected_data = mean_samplingpoint[mean_samplingpoint['pollutant'] == selected_pollution]\n",
    "\n",
    "    # Sort the data by country name\n",
    "    selected_data = selected_data.sort_values(by='network_countrycode')\n",
    "\n",
    "    # Create the plotly figure\n",
    "    fig = px.scatter(\n",
    "        selected_data,\n",
    "        x='network_countrycode',\n",
    "        y='value_numeric',\n",
    "        size='value_numeric',\n",
    "        color='value_numeric',\n",
    "        hover_name='network_countrycode',\n",
    "        labels={'network_countrycode': 'Country', 'value_numeric': f'{selected_pollution} Value ({selected_data[\"unit\"].iloc[0]})'},\n",
    "        title=f'{selected_pollution} Pollution by Country',\n",
    "    )\n",
    "    fig.update_layout(\n",
    "        xaxis={'tickangle': 90},\n",
    "        yaxis={'range': [-5, selected_data['value_numeric'].max() * 1.2]},\n",
    "        coloraxis_colorbar={'title': f'{selected_pollution} Value ({selected_data[\"unit\"].iloc[0]})'}\n",
    "    )\n",
    "    return fig\n",
    "# Define the callback function\n",
    "@app.callback(\n",
    "    Output('graph', 'figure'),  # Specify the 'graph' id as the output\n",
    "    Input('country-dropdown', 'value'),\n",
    "    Input('pollutant-radio', 'value')\n",
    ")\n",
    "def update_chart(country, pollutant):\n",
    "    filtered_data = filter_data(country, pollutant)\n",
    "    if len(filtered_data) > 0:\n",
    "        title = f\"Measurement of {pollutant} pollution in {country} in the last 48 hours\"\n",
    "\n",
    "        # Plot the data using Plotly\n",
    "        fig = go.Figure(data=go.Scatter(\n",
    "            x=list(range(48)),\n",
    "            y=filtered_data['value_numeric'],\n",
    "            mode='markers',\n",
    "            marker=dict(\n",
    "                color=filtered_data['value_numeric'],\n",
    "                colorscale='jet',\n",
    "                size=10,\n",
    "                colorbar=dict(\n",
    "                    title=f'{pollutant} ({filtered_data[\"value_unit\"].iloc[0]})',\n",
    "                    yanchor='middle', y=0.5,\n",
    "                    len=0.75, lenmode='fraction',\n",
    "                    thickness=20, thicknessmode='pixels',\n",
    "                    xanchor='left', x=1.05,\n",
    "                )\n",
    "            ),\n",
    "            name='Data'\n",
    "        ))\n",
    "        fig.update_layout(\n",
    "            title=title,\n",
    "            xaxis_title='Time',\n",
    "            yaxis_title=f'{pollutant} ({filtered_data[\"value_unit\"].iloc[0]})',\n",
    "            coloraxis_showscale=False,\n",
    "            margin=dict(l=50, r=150, b=50, t=80),\n",
    "            coloraxis_colorbar=dict(\n",
    "                title_font=dict(size=14),\n",
    "                tickfont=dict(size=12),\n",
    "            ),\n",
    "            legend=dict(\n",
    "                title='Statistics',\n",
    "                yanchor='top',\n",
    "                y=0.99,\n",
    "                xanchor='left',\n",
    "                x=1.01,\n",
    "                bgcolor='rgba(255, 255, 255, 0.7)',\n",
    "                bordercolor='rgba(0, 0, 0, 0.5)',\n",
    "                borderwidth=1,\n",
    "                itemsizing='constant',\n",
    "                itemclick='toggle',\n",
    "                itemdoubleclick='toggleothers',\n",
    "                font=dict(size=12),\n",
    "                traceorder='normal'\n",
    "            )\n",
    "        )\n",
    "\n",
    "        return fig\n",
    "    else:\n",
    "        error_message = f\"We don't have data for {pollutant} in {country}. Please try another pollutant or country.\"\n",
    "        return error_message\n",
    "# Define callback to update the map's iframe content based on the selected pollution type\n",
    "@app.callback(\n",
    "    Output('map-iframe', 'srcDoc'),\n",
    "    [Input('pollution-type-radio', 'value')]\n",
    ")\n",
    "def update_map(pollution_type):\n",
    "    updated_map = generate_heatmap(pollution_type)\n",
    "    return updated_map\n",
    "# Callbacks to update the download links\n",
    "@app.callback(\n",
    "    Output('download-merged-data', 'href'),\n",
    "    Output('download-mean-samplingpoint', 'href'),\n",
    "    Input('download-merged-data', 'n_clicks'),\n",
    "    Input('download-mean-samplingpoint', 'n_clicks')\n",
    ")\n",
    "def update_download_links(merged_data_clicks, mean_samplingpoint_clicks):\n",
    "    ctx = dash.callback_context\n",
    "    if ctx.triggered:\n",
    "        triggered_id = ctx.triggered[0]['prop_id'].split('.')[0]\n",
    "        if triggered_id == 'download-merged-data':\n",
    "            df = merged_data\n",
    "            filename = 'merged_data.csv'\n",
    "        elif triggered_id == 'download-mean-samplingpoint':\n",
    "            df = mean_samplingpoint\n",
    "            filename = 'mean_samplingpoint.csv'\n",
    "        else:\n",
    "            df = None\n",
    "            filename = None\n",
    "        \n",
    "        if df is not None:\n",
    "            # Create a CSV string from the dataframe\n",
    "            csv_string = df.to_csv(index=False, encoding='utf-8')\n",
    "            csv_string = \"data:text/csv;charset=utf-8,\" + base64.b64encode(csv_string.encode()).decode()\n",
    "            return csv_string, csv_string\n",
    "    \n",
    "    # Return empty href for initial state\n",
    "    return '', ''\n",
    "# Run the app\n",
    "if __name__ == '__main__':\n",
    "    app.run_server(mode='inline',port=9012)\n",
    "    # app.run_server(mode='external',port=9012)\n",
    "    # app.run_server(mode='jupyterlab',port=9012)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8def11f0-b08f-4dbb-8eae-de635c652621",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
